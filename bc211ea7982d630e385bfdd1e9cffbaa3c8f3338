{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "dd5c29b0_cba3f6af",
        "filename": "/COMMIT_MSG",
        "patchSetId": 2
      },
      "lineNbr": 14,
      "author": {
        "id": 1
      },
      "writtenOn": "2021-12-15T18:46:35Z",
      "side": 1,
      "message": "At least with mysql, we may be splitting hairs here, and to be honest, I\u0027m not sure it\u0027s worth the complexity.\n\nLooking at the query plan in mysql for both the openstack and zuul tenants, mysql always says it\u0027s going to examine more rows if I add a minimum.  In the best case, it\u0027s about 2x the number of rows.  In some cases, it\u0027s much more.\n\nSince the query is already sorted descending, both the estimated and actual runtimes should be very close for page 1, then theoretically adding the minimum should gain an advantage as we go to more and more pages, as we don\u0027t need to gather as many items past our limit.  However, the database is already smart enough not to gather more items past our limit, so there really isn\u0027t an optimization to be made there.  They both run in a range of 0.00 to 0.02 seconds; effectively immeasurable under these conditions.\n\nAnd indeed, if I run the query with an offset of 20000, it takes 2.5 seconds with the minimum, and 1.86 seconds without -- confirming what the query planner estimates -- it\u0027s more work to add the minimum check.\n\nBut there are a lot of variables; is there a situation where you have confirmed better performance?",
      "revId": "bc211ea7982d630e385bfdd1e9cffbaa3c8f3338",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "21102220_a8233498",
        "filename": "/COMMIT_MSG",
        "patchSetId": 2
      },
      "lineNbr": 14,
      "author": {
        "id": 9311
      },
      "writtenOn": "2021-12-15T18:51:33Z",
      "side": 1,
      "message": "When crawling the builds, it can be error prone to rely on skip/limit when new builds are added between the queries, resulting in duplicated result. If I understand correctly, using the idx would ensure consistent result.",
      "parentUuid": "dd5c29b0_cba3f6af",
      "revId": "bc211ea7982d630e385bfdd1e9cffbaa3c8f3338",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "cde22c83_871ad979",
        "filename": "/COMMIT_MSG",
        "patchSetId": 2
      },
      "lineNbr": 14,
      "author": {
        "id": 1
      },
      "writtenOn": "2021-12-15T19:03:45Z",
      "side": 1,
      "message": "The commit message didn\u0027t mention that.  Using this without the offset does make a difference in query time.  Times remain about the same at page 1, but offset times increase with more pages and min/max times stay constant.\n\nI still have questions about how that will actually work (what happens when you\u0027re on page 2 and you hit back and there are more than 1 page worth of new builds on page 1?).  But we can address those later.",
      "revId": "bc211ea7982d630e385bfdd1e9cffbaa3c8f3338",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "d858cf69_cddecb45",
        "filename": "zuul/web/__init__.py",
        "patchSetId": 2
      },
      "lineNbr": 1311,
      "author": {
        "id": 9311
      },
      "writtenOn": "2021-12-15T18:07:30Z",
      "side": 1,
      "message": "nit: a `def int_or_none(param)` helper function could be useful here.",
      "revId": "bc211ea7982d630e385bfdd1e9cffbaa3c8f3338",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    }
  ]
}