{
  "comments": [
    {
      "key": {
        "uuid": "bfdaf3ff_8f7cd11f",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 5
      },
      "lineNbr": 64,
      "author": {
        "id": 3099
      },
      "writtenOn": "2019-01-17T16:53:59Z",
      "side": 1,
      "message": "This raises some concerns for me. Notably:\n\n* Lots of events (which we are sure to have) will cause event sequence numbers to rollover. Could that put a wrinkle in processing the events in order?\n\n* Assuming you plan to use the kazoo queue recipe, that is documented to be buggy, causing memory leaks over long periods of usage. https://kazoo.readthedocs.io/en/latest/api/recipe/queue.html#module-kazoo.recipe.queue",
      "range": {
        "startLine": 64,
        "startChar": 0,
        "endLine": 64,
        "endChar": 68
      },
      "revId": "5e9dea3be7c11fb0826727676907b6e37bd09f48",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "bfdaf3ff_cf02d96f",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 5
      },
      "lineNbr": 64,
      "author": {
        "id": 1
      },
      "writtenOn": "2019-01-17T16:59:40Z",
      "side": 1,
      "message": "We could look a little harder at dropping these event queues.  Zuul 1.0\u0027s scheduler was very much event-driven, with the idea that if, say, a build finished, we only needed to look at that queue item.  But that was error-prone, and Zuul has gotten much more complex since then.  Now we do some actions on events, but not very much, and mostly we just use the events to set a flag saying \"run the pipeline queue processor\".  We might be able to do the things we need to do quickly with watches on objects and otherwise just run the queue processor.  If folks think this approach is worthwhile, I can take a closer look at the current queues and figure out how we could rearrange them.",
      "revId": "5e9dea3be7c11fb0826727676907b6e37bd09f48",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "bfdaf3ff_d55cbf7f",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 5
      },
      "lineNbr": 169,
      "author": {
        "id": 1
      },
      "writtenOn": "2019-01-16T18:50:16Z",
      "side": 1,
      "message": "We can also segment it if necessary.  /zuul/config/project/branch/jobs/ could be a directory of json blobs.  We wouldn\u0027t need to make one zobject per job -- we would end up with too many zobjects that way.  But we could have /zuul/config/project/branch/jobs/1 be the first 100 jobs, and jobs/2 be the next 100.  That way we remove the size limitation, and when small changes happen in big repos, we reduce the amount of data we need to change in zk (for example, we might only replace the jobs/2 object if job #157 is updated).",
      "revId": "5e9dea3be7c11fb0826727676907b6e37bd09f48",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "bfdaf3ff_f53ea3d8",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 5
      },
      "lineNbr": 169,
      "author": {
        "id": 16068
      },
      "writtenOn": "2019-01-16T18:58:58Z",
      "side": 1,
      "message": "I like this idea",
      "parentUuid": "bfdaf3ff_d55cbf7f",
      "revId": "5e9dea3be7c11fb0826727676907b6e37bd09f48",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "5faad753_4c91fc46",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 5
      },
      "lineNbr": 171,
      "author": {
        "id": 30637
      },
      "writtenOn": "2019-09-13T14:36:12Z",
      "side": 1,
      "message": "I would worry that if the compression\u0027s purpose it to fit certain limit size turning it off may cause some problems (in case of e.g. debugging). Therefore maybe a more broken up format, i.e., the one mentioned above may be a better approach.",
      "range": {
        "startLine": 170,
        "startChar": 7,
        "endLine": 171,
        "endChar": 55
      },
      "revId": "5e9dea3be7c11fb0826727676907b6e37bd09f48",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "bfdaf3ff_f55f836f",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 5
      },
      "lineNbr": 211,
      "author": {
        "id": 1
      },
      "writtenOn": "2019-01-16T18:50:16Z",
      "side": 1,
      "message": "Is there a reason to still have sql reporters in pipelines?  Why not just attach them in tenants (so different tenants can use different sql connections, but each tenant always uses exactly one)?",
      "revId": "5e9dea3be7c11fb0826727676907b6e37bd09f48",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "bfdaf3ff_f570e3de",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 5
      },
      "lineNbr": 211,
      "author": {
        "id": 16068
      },
      "writtenOn": "2019-01-16T18:58:58Z",
      "side": 1,
      "message": "The reason was mostly backwards compatibility as today one can choose to report per pipeline. But I\u0027m open to just remove this as this is probably just a hypothetical use case.",
      "parentUuid": "bfdaf3ff_f55f836f",
      "revId": "5e9dea3be7c11fb0826727676907b6e37bd09f48",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "bfdaf3ff_70e08197",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 5
      },
      "lineNbr": 211,
      "author": {
        "id": 1
      },
      "writtenOn": "2019-01-16T19:33:22Z",
      "side": 1,
      "message": "I feel like with the API and dashboard allowing flexible queries (including pipeline), we\u0027ve largely superceded any use like that.",
      "revId": "5e9dea3be7c11fb0826727676907b6e37bd09f48",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "bfdaf3ff_d80cd342",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 5
      },
      "lineNbr": 211,
      "author": {
        "id": 16068
      },
      "writtenOn": "2019-01-18T08:47:58Z",
      "side": 1,
      "message": "Ok, I\u0027m happy to remove the sql reporters from the pipeline config entirely. So we could define an sql connection as default in zuul.conf and make it possible to override it per tenant in the tenant config.",
      "revId": "5e9dea3be7c11fb0826727676907b6e37bd09f48",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "5faad753_2c8600dd",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 5
      },
      "lineNbr": 211,
      "author": {
        "id": 30637
      },
      "writtenOn": "2019-09-13T14:36:12Z",
      "side": 1,
      "message": "Since the purpose of this is High-Availability shouldn\u0027t we think about some HA-Store. An SQL database feels a bit like a possible future bottleneck here when multiple, possibly many, schedulers will try to write there simultaneously.",
      "parentUuid": "bfdaf3ff_d80cd342",
      "revId": "5e9dea3be7c11fb0826727676907b6e37bd09f48",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "5faad753_ec546855",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 5
      },
      "lineNbr": 214,
      "author": {
        "id": 30637
      },
      "writtenOn": "2019-09-13T14:36:12Z",
      "side": 1,
      "message": "If the purpose of this is to know the times of last 10 successful builds wouldn\u0027t it be worth to think about storing  it in Zookeeper too. And by that limiting the complexity of both, code and deployment - less mandatory deployment nodes?",
      "range": {
        "startLine": 213,
        "startChar": 0,
        "endLine": 214,
        "endChar": 35
      },
      "revId": "5e9dea3be7c11fb0826727676907b6e37bd09f48",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "bfdaf3ff_9556375c",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 5
      },
      "lineNbr": 287,
      "author": {
        "id": 1
      },
      "writtenOn": "2019-01-16T18:50:16Z",
      "side": 1,
      "message": "I don\u0027t think we should include the max processing time to start with; I think that will introduce a lot of edge cases we would need to handle and complexity.  If we find we need it we can add it later.",
      "revId": "5e9dea3be7c11fb0826727676907b6e37bd09f48",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "bfdaf3ff_b5849bb2",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 5
      },
      "lineNbr": 287,
      "author": {
        "id": 16068
      },
      "writtenOn": "2019-01-16T18:58:58Z",
      "side": 1,
      "message": "++",
      "parentUuid": "bfdaf3ff_9556375c",
      "revId": "5e9dea3be7c11fb0826727676907b6e37bd09f48",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "bfdaf3ff_4f4fc933",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 5
      },
      "lineNbr": 317,
      "author": {
        "id": 1
      },
      "writtenOn": "2019-01-17T16:46:16Z",
      "side": 1,
      "message": "We should probably add a section on work items.  It would be good to list some of the major steps we need to do, so we can get an idea of how much work will need to be done, whether we can split it up among different authors, and how we should handle merging and releasing.\n\nParticularly, it would be good to figure out whether we want to break it up into a series of moderate changes (such as \"require sql\", \"zk ingestor\", \"zk executor\", \"zk scheduler\"), each of which gets a 3.x release with an upgrade note, or whether we want to maintain a long stack of changes in gerrit with rebasing and land it all then release 4.0, or whether we want to make a feature branch.  I think making the list of work items as a start will help us find the right answer.",
      "revId": "5e9dea3be7c11fb0826727676907b6e37bd09f48",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "bfdaf3ff_7805a713",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 5
      },
      "lineNbr": 317,
      "author": {
        "id": 16068
      },
      "writtenOn": "2019-01-18T08:47:58Z",
      "side": 1,
      "message": "Good point. I\u0027ll add this. If we can manage it (and I hope this works out) I\u0027d be in favor of a series of moderate changes instead of a big bang release.",
      "revId": "5e9dea3be7c11fb0826727676907b6e37bd09f48",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    }
  ]
}