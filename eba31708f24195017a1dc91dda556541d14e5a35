{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "af333d65_01864036",
        "filename": "/COMMIT_MSG",
        "patchSetId": 2
      },
      "lineNbr": 10,
      "author": {
        "id": 1
      },
      "writtenOn": "2021-10-11T21:55:47Z",
      "side": 1,
      "message": "Why do we need to do this?  Why can\u0027t we continue using the current random buildset UUID?  We already re-set it at the appropriate times.\n\nI think there may be a fundamental problem with this: nothing in NNFI assumes that we can\u0027t recreate a queue sequence a second time.  That used to happen quite frequently in Zuul.  Fixing the job graph at global buildset creation time has greatly reduced the opportunity for that, but I don\u0027t want to assume that doing something like running a promote on the item at the top of the queue won\u0027t still be able to do it.  Or we might even write a \"restart builds\" command.\n\nTo elaborate/clarify: imagine we have A\u003c-B in the queue.  We create buildests #1 and #2 respectively.  A fails, so we have A as a severed head, and B as the next head.  B gets buildset #3 created for it.  Then something happens and A\u003c-B are sequenced again.  We should get buildset #4 for B; we should not re-use buildset #2.",
      "revId": "eba31708f24195017a1dc91dda556541d14e5a35",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "be9e9d3f_1ab47d82",
        "filename": "/COMMIT_MSG",
        "patchSetId": 2
      },
      "lineNbr": 10,
      "author": {
        "id": 27582
      },
      "writtenOn": "2021-10-12T07:59:49Z",
      "side": 1,
      "message": "What would be the event that leads to A and B being sequenced again? Wouldn\u0027t this only be possible in case there is another item X ahead of A and B that failed? In that case we\u0027d get a different buildset UUID because the buildsets ahead have changed.\n\nRegarding the \"why\", please see my response below.",
      "parentUuid": "af333d65_01864036",
      "revId": "eba31708f24195017a1dc91dda556541d14e5a35",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "ac50df75_0744465a",
        "filename": "/COMMIT_MSG",
        "patchSetId": 2
      },
      "lineNbr": 10,
      "author": {
        "id": 27582
      },
      "writtenOn": "2021-10-12T08:05:37Z",
      "side": 1,
      "message": "Sorry, I think I did not fully understand what you mean by \"sequenced again\". In the case of a \"restart builds\" command I think it should be fine to keep the same buildset. We could just restart the builds as the position in the queue did not change and everything else should be still valid.",
      "parentUuid": "be9e9d3f_1ab47d82",
      "revId": "eba31708f24195017a1dc91dda556541d14e5a35",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "8df9ac66_2e61b385",
        "filename": "/COMMIT_MSG",
        "patchSetId": 2
      },
      "lineNbr": 10,
      "author": {
        "id": 1
      },
      "writtenOn": "2021-10-12T16:28:23Z",
      "side": 1,
      "message": "I don\u0027t know what would lead A and B to being sequenced again, but I know that the algorithm allows for it and the software as written now would support it.  I think it could have happened in the past before global repo state was implemented.  And I don\u0027t want to prevent it from happening again in the future.  In short, I have no concrete current case for it, but I think it\u0027s important for us to allow it.\n\nI don\u0027t think we can re-use the same buildset.  The first time through, the jobs may have run to completion.  The second time through they may also run to completion.  We would have database entries with a single buildset with duplicate \"final\" jobs, which is not something we intend to support.  It makes much more sense for those to be different buildsets.",
      "revId": "eba31708f24195017a1dc91dda556541d14e5a35",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "10cd8f54_1e569c9e",
        "filename": "/COMMIT_MSG",
        "patchSetId": 2
      },
      "lineNbr": 23,
      "author": {
        "id": 1
      },
      "writtenOn": "2021-10-11T21:55:47Z",
      "side": 1,
      "message": "Yes, there is as little logic as possible in the re-enqueue method.  The idea behind the NNFI method is that it converges on the correct state.  If any conditions are different compared to the current state, then the method corrects the state to match the current conditions, and this includes creating new buildsets if needed.  The re-enqueue method should definitely not re-implement the NNFI algorithm.  It should just get the item into the queue and then the scheduler should always process the pipeline after that is complete in order to perform corrective action.",
      "revId": "eba31708f24195017a1dc91dda556541d14e5a35",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "feaafb87_a0e3020f",
        "filename": "/COMMIT_MSG",
        "patchSetId": 2
      },
      "lineNbr": 23,
      "author": {
        "id": 27582
      },
      "writtenOn": "2021-10-12T07:59:49Z",
      "side": 1,
      "message": "I\u0027d be totally fine with the re-enqueue doing only what\u0027s necessary, but I think there are currently cases where the buildset of an item is still used and NOT reset by the pipeline manager later on. E.g. see the failing test case test_live_reconfiguration_shared_queue_removed.\n\nI\u0027m fine with arguing that the items ahead/behind pointers will eventually converge to the correct state and that they might be wrong after a re-enqueue. However, in the mentioned test the old buildset was still used and not reset even though the items ahead moved to a different queue.\n\nMaybe there is a different way to fix this, but I think some information about the previous order of the items is lost during re-enqueue and the deterministic buildset UUID allows us to detect such ordering changes.",
      "parentUuid": "10cd8f54_1e569c9e",
      "revId": "eba31708f24195017a1dc91dda556541d14e5a35",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "fe0a5390_c40f06cd",
        "filename": "/COMMIT_MSG",
        "patchSetId": 2
      },
      "lineNbr": 23,
      "author": {
        "id": 1
      },
      "writtenOn": "2021-10-12T16:28:23Z",
      "side": 1,
      "message": "I\u0027ll look into that test so I understand more of what\u0027s going on.  But maybe if we need something like this we could explicitly list the items in the buildset, so we can invalidate it that way.  So the item ahead sequence would be one reason to invalidate a buildset (but perhaps not the only one, and we wouldn\u0027t assume that every item ahead sequence maps 1:1 to a buildset).",
      "revId": "eba31708f24195017a1dc91dda556541d14e5a35",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    }
  ]
}