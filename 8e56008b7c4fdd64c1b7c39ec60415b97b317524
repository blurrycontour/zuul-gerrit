{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "dc4d0ac6_04d44e4f",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 9
      },
      "lineNbr": 0,
      "author": {
        "id": 4146
      },
      "writtenOn": "2022-02-08T23:13:03Z",
      "side": 1,
      "message": "recheck this failed in the sos test_semaphore test. Not sure if related yet, but figure a recheck might give us more data.",
      "revId": "8e56008b7c4fdd64c1b7c39ec60415b97b317524",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "072e4c55_bbb77ffd",
        "filename": "zuul/manager/__init__.py",
        "patchSetId": 9
      },
      "lineNbr": 95,
      "author": {
        "id": 1
      },
      "writtenOn": "2022-02-08T23:18:49Z",
      "side": 1,
      "message": "Let\u0027s clarify this a bit.\n\nWe call this after loading a tenant.  If we are the first to reconfigure a tenant, then the pipeline state layout uuid will be the old value, and layout.uuit will be the new one.  In that case, we need to call the pipeline state reset method in order to move the queues currently in zk to \"old_queues\" so that the next processing pass will re-enqueue them.\n\nOtherwise, we\u0027re note the first to reconfigure the tenant, meaning that some other scheduler has already done that, so we can skip it.  We only need to update our local object pointers.\n\nThere\u0027s one more case: we\u0027re a scheduler that\u0027s starting up and joining an existing system.  Now, there\u0027s a side effect of calling the reset method in the first case: it also refreshes the objects from ZK.  That\u0027s important in this case because that\u0027s going to initially load the queue items and all the places in our code which are \"best-effort\", like stats, will have a chance of having something accurate.\n\nIn other words, by making this optimization, we\u0027re reducing the accuracy of our best-effort routines, especially in the case of scheduler startup.  Maybe that\u0027s okay, but it\u0027s worth noting.",
      "revId": "8e56008b7c4fdd64c1b7c39ec60415b97b317524",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "ad536a04_ce1a3671",
        "filename": "zuul/manager/__init__.py",
        "patchSetId": 9
      },
      "lineNbr": 95,
      "author": {
        "id": 4146
      },
      "writtenOn": "2022-02-08T23:44:12Z",
      "side": 1,
      "message": "\u003e Let\u0027s clarify this a bit.\n\u003e \n\u003e We call this after loading a tenant.  If we are the first to reconfigure a tenant, then the pipeline state layout uuid will be the old value, and layout.uuit will be the new one.  In that case, we need to call the pipeline state reset method in order to move the queues currently in zk to \"old_queues\" so that the next processing pass will re-enqueue them.\n\nJust making sure I understand this properly. The change as proposed doesn\u0027t affect this scenario right? We\u0027ll fall through since the uuid values won\u0027t match and then we call resetOrCreate()?\n\n\u003e \n\u003e Otherwise, we\u0027re note the first to reconfigure the tenant, meaning that some other scheduler has already done that, so we can skip it.  We only need to update our local object pointers.\n\u003e \n\u003e There\u0027s one more case: we\u0027re a scheduler that\u0027s starting up and joining an existing system.  Now, there\u0027s a side effect of calling the reset method in the first case: it also refreshes the objects from ZK.  That\u0027s important in this case because that\u0027s going to initially load the queue items and all the places in our code which are \"best-effort\", like stats, will have a chance of having something accurate.\n\nThe failing test_semaphore test case is failing due to the new scheduler not having done this and the build being unable to run because the scheduler that does have this info is not holding the lock?\n\n\u003e \n\u003e In other words, by making this optimization, we\u0027re reducing the accuracy of our best-effort routines, especially in the case of scheduler startup.  Maybe that\u0027s okay, but it\u0027s worth noting.",
      "parentUuid": "072e4c55_bbb77ffd",
      "revId": "8e56008b7c4fdd64c1b7c39ec60415b97b317524",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "197418b5_67ff21af",
        "filename": "zuul/manager/__init__.py",
        "patchSetId": 9
      },
      "lineNbr": 95,
      "author": {
        "id": 1
      },
      "writtenOn": "2022-02-09T00:00:19Z",
      "side": 1,
      "message": "\u003e Just making sure I understand this properly. The change as proposed doesn\u0027t affect this scenario right? We\u0027ll fall through since the uuid values won\u0027t match and then we call resetOrCreate()?\n\nYep.  Just exposition.  :)\n\n\u003e The failing test_semaphore test case is failing due to the new scheduler not having done this and the build\nbeing unable to run because the scheduler that does have this info is not holding the lock?\n\nAlmost -- it\u0027s failing due to the new scheduler not having done this and then running the semaphore cleanup method and detecting it as a leaked semaphore since it doesn\u0027t have the build info.  The semaphore fix change corrects this by explicitly doing a lookup in ZK in the cleanup method.",
      "revId": "8e56008b7c4fdd64c1b7c39ec60415b97b317524",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "df23088c_e2565d9a",
        "filename": "zuul/scheduler.py",
        "patchSetId": 9
      },
      "lineNbr": 822,
      "author": {
        "id": 4146
      },
      "writtenOn": "2022-02-08T23:44:12Z",
      "side": 1,
      "message": "Is this a functional change?",
      "revId": "8e56008b7c4fdd64c1b7c39ec60415b97b317524",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "ef297599_730dbafc",
        "filename": "zuul/scheduler.py",
        "patchSetId": 9
      },
      "lineNbr": 822,
      "author": {
        "id": 1
      },
      "writtenOn": "2022-02-09T00:00:19Z",
      "side": 1,
      "message": "Yes, as it turns out.  lock_ctx is a generator, and tlock is the actual lock...",
      "revId": "8e56008b7c4fdd64c1b7c39ec60415b97b317524",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "ba994a01_57b3f257",
        "filename": "zuul/scheduler.py",
        "patchSetId": 9
      },
      "lineNbr": 822,
      "author": {
        "id": 4146
      },
      "writtenOn": "2022-02-09T00:10:05Z",
      "side": 1,
      "message": "Ah yup tenant_write_lock returns a SessionAwareWriteLock which we must then enter a context with to actually acquire the lock.",
      "parentUuid": "ef297599_730dbafc",
      "revId": "8e56008b7c4fdd64c1b7c39ec60415b97b317524",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "b8658872_84023c63",
        "filename": "zuul/scheduler.py",
        "patchSetId": 9
      },
      "lineNbr": 845,
      "author": {
        "id": 1
      },
      "writtenOn": "2022-02-09T00:00:19Z",
      "side": 1,
      "message": "...that we pass in here.  Apparently this is untested code, because it does fail if I stick a refresh here.  Ideally, we would move this into its own change and add a test.",
      "revId": "8e56008b7c4fdd64c1b7c39ec60415b97b317524",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "2bd985d9_aa70e707",
        "filename": "zuul/scheduler.py",
        "patchSetId": 9
      },
      "lineNbr": 1488,
      "author": {
        "id": 1
      },
      "writtenOn": "2022-02-08T23:18:49Z",
      "side": 1,
      "message": "This is not true anymore.  This change removes the refresh that happens on loading a tenant, so now we can enter this clause with an out of date pipeline state.  When a scheduler starts and joins an existing system, it will have no items in its queues until it manages to process them.\n\nSee the other comment about the side effect of refresh on startup.\n\nI think we need to do one of the following here:\n\n1) Remove this stats emission altogether.  In \u003cv5 it\u0027s purpose was to reset gauges on startup.  Now the gauges aren\u0027t likely to be wrong for very long after a reconfiguration (if they\u0027re wrong at all).  And as written, it can zero out the gauges when a scheduler comes online.\n\n2) Add a refresh to this location (as in the earlier patchset).\n\n3) Add a refresh to the end of the config priming method so that we load some data in on scheduler startup for best-effort methods like this.\n\nMy preference is #1.",
      "revId": "8e56008b7c4fdd64c1b7c39ec60415b97b317524",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    }
  ]
}