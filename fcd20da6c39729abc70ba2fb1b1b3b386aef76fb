{
  "comments": [
    {
      "key": {
        "uuid": "3f79a3b5_e8bec27b",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 125,
      "author": {
        "id": 7069
      },
      "writtenOn": "2018-12-05T08:18:10Z",
      "side": 1,
      "message": "Why would the active event gathering go into zuul-web? (Seems more appropriate for the passive one).",
      "range": {
        "startLine": 125,
        "startChar": 33,
        "endLine": 125,
        "endChar": 42
      },
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_b1bce0b6",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 133,
      "author": {
        "id": 1
      },
      "writtenOn": "2018-12-03T22:42:14Z",
      "side": 1,
      "message": "Non-leaders could watch both the incoming and outgoing stream, keep a running history of the last X minutes of events which haven\u0027t made it into zookeeper, and, if they become leader, report those from the backlog.\n\nIt\u0027s a lot like B, but storing the data in memory twice (in the ingestor processes) instead of in ZK twice.",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_966add4d",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 133,
      "author": {
        "id": 6488
      },
      "writtenOn": "2018-12-04T18:26:44Z",
      "side": 1,
      "message": "I was thinking the same thing, and I like it. But I\u0027m also concerned we\u0027re over-valueing 100% ingestion.",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_8c841059",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 133,
      "author": {
        "id": 16068
      },
      "writtenOn": "2018-12-04T20:01:36Z",
      "side": 1,
      "message": "How about we start with pure leader election and support a standalong ingestor? That way we have most of the time ingestion and could later extend that to the 100% variant if we want to.\n\nThinking more about that, in case of connection drops and reconnects whithout a crash of the ingestor we can loose events. So if we want 100% ingestion we would also need to cancel leadership instead of a reconnect.",
      "parentUuid": "3f79a3b5_966add4d",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_3687490d",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 140,
      "author": {
        "id": 6488
      },
      "writtenOn": "2018-12-04T18:26:44Z",
      "side": 1,
      "message": "Dedupe by hash is actually the perfect strategy. Don\u0027t even store an event if it already exists. Ordering them can be a bit complex though, as the receivers will need to keep track of which event they got previously and assign an order counter when they write, but if they don\u0027t write because the record already exists, they need to ensure that they adapt their ordering properly. I believe we\u0027ve *almost* reimplemented Kafka at that point.",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_d1b71cd1",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 143,
      "author": {
        "id": 1
      },
      "writtenOn": "2018-12-03T22:42:14Z",
      "side": 1,
      "message": "We could consider not supporting multiple ingestors, and instead make them standalone processes which are very small and quick to restart.  I think this would be acceptable, but if we can do A or B, we should.  They degrade to this case anyway if you only run one.",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_568a0512",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 143,
      "author": {
        "id": 6488
      },
      "writtenOn": "2018-12-04T18:26:44Z",
      "side": 1,
      "message": "Is the stream implemented as a safe messaging system? IIRC, it\u0027s just a stream, and as such, messages will be sent if there are subscribers, and if not, they just go into the bit bucket. As such I\u0027d say it\u0027s got to be expected that we might miss messages (such as when the ingestors are partitioned from Gerrit), and so just keeping the ingestor light, reliable, and consistent with a very low leader election/lock timeout would be the simplest course.",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_f690f143",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 149,
      "author": {
        "id": 6488
      },
      "writtenOn": "2018-12-04T18:26:44Z",
      "side": 1,
      "message": "s/Guthub/Github/",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_0ceec01f",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 149,
      "author": {
        "id": 16068
      },
      "writtenOn": "2018-12-04T20:01:36Z",
      "side": 1,
      "message": "oops",
      "parentUuid": "3f79a3b5_f690f143",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_16948d34",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 152,
      "author": {
        "id": 6488
      },
      "writtenOn": "2018-12-04T18:26:44Z",
      "side": 1,
      "message": "Did you mean to remove the \"it won\u0027t harm\" phrase here?",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_ec38249f",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 152,
      "author": {
        "id": 16068
      },
      "writtenOn": "2018-12-04T20:01:36Z",
      "side": 1,
      "message": "I think I can remove the whole sentence as this was written under the assumption that the receiver performs deduplication where it\u0027s actually better to do this on the writer side.",
      "parentUuid": "3f79a3b5_16948d34",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_e3f6e32c",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 179,
      "author": {
        "id": 7069
      },
      "writtenOn": "2018-12-05T08:18:10Z",
      "side": 1,
      "message": "by a?",
      "range": {
        "startLine": 179,
        "startChar": 40,
        "endLine": 179,
        "endChar": 50
      },
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_71d408f1",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 181,
      "author": {
        "id": 1
      },
      "writtenOn": "2018-12-03T22:42:14Z",
      "side": 1,
      "message": "This is where the biggest unanswered questions are.\n\nAre you suggesting we store the parsed config as a single object, or is that just the root, and under there we would have \".../jobs/...\" etc?\n\nWe can still store the parsed branch config globally.  When a change happens, we can just lock the global config and whoever gets the lock gets to update it.\n\nIf we only store the global config, should we also store per-tenant configs?  Should they reference global config objects \"by reference\" (eg, znode ids?).\n\nSame question for dynamic layouts (ie, per-change configs).\n\nIn general, these suggest two ends of a spectrum: storing a lot of config in zk, or storing very little.  If we store the global parsed config, per-tenant layout, and (where necessary) per-change layout, we\u0027ll be storing a lot in ZK.\n\nIf we wanted to store as little as possible, I\u0027d suggest only storing the global parsed config in zk, and then have each scheduler process generate its own copy of the per-tenant config (whenever the underlying objects or configuration changed).  The zuul-web process could do the same so that it sees the same view of the data.  And whenever a dynamic layout is needed, the scheduler which is processing that pipeline at the time can generate the dynamic layout, keep it in memory until it has finished the pipeline, then discard it (after having recorded the frozen jobs in ZK).\n\nThe middle ground is probably closer to what you describe -- keep both the global and per-tenant configs in zk (perhaps with objects by reference), but don\u0027t store dynamic layouts in ZK.  That has the best scaling performance too (in that it doesn\u0027t cause ZK to scale eponentially with change volume).",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_b69a795e",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 181,
      "author": {
        "id": 6488
      },
      "writtenOn": "2018-12-04T18:26:44Z",
      "side": 1,
      "message": "I think as little as possible should be in ZK. If it can be re-calculated in a small amount of time, it should just be in memory, but if it\u0027s something large like the global config, it makes sense to maintain a consistent cache for schedulers to share and not have to re-fetch all the git trees.",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_0cb1e000",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 181,
      "author": {
        "id": 16068
      },
      "writtenOn": "2018-12-04T20:01:36Z",
      "side": 1,
      "message": "My thinking was that we store the per branch parsed config (which you are referring to as global config?) as json blobs under this path. This way we can quickly recalculate the layout of a tenant without having to save too much data in zk which we should avoid. I suggested to store this under a tenant specific path in order to not having to care about race conditions when reconfiguring several tenants sharing a few shared at the same time. I\u0027m not sure if that\u0027s a problem so that\u0027s just pure precaution. We also can keep that really global and protect the updates with locks per project. That way we don\u0027t serialize reconfigurations of several tenants.\n\nThe per tenant config (current non dynamic layout) could be easily cached in memory and updated by each scheduler based on the version and cversion (child version) of each project that is part of the tenant. In case a version or cversion changed, we would need to inject a tenant reconfiguration (possibly without asking the mergers) to rebuild the layout of the tenant.\n\nRegarding the dynamic layout. I also thought that we should just store the frozen jobs in zk as part of the pipeline state. After that we probably don\u0027t need the dynamic layout so there should be no need to store it in zk.",
      "parentUuid": "3f79a3b5_b69a795e",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_91d764f4",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 198,
      "author": {
        "id": 1
      },
      "writtenOn": "2018-12-03T22:42:14Z",
      "side": 1,
      "message": "Or, we could make the SQL database integrated (ie, not a reporter) and drop the times database.",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_d695b530",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 198,
      "author": {
        "id": 6488
      },
      "writtenOn": "2018-12-04T18:26:44Z",
      "side": 1,
      "message": "+1 for that, I think it\u0027s clear that the DB isn\u0027t quite in the right place as a reporter anyway.",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_4cb91879",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 198,
      "author": {
        "id": 16068
      },
      "writtenOn": "2018-12-04T20:01:36Z",
      "side": 1,
      "message": "+1 for moving sql reporting into zuul itself. But I\u0027m not sure if we should move the times database into sql. I hadn\u0027t yet a really close look into how it exactly works yet. I just saw that the times database consists of small binary files per project/branch/job.",
      "parentUuid": "3f79a3b5_d695b530",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_636173d5",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 198,
      "author": {
        "id": 7069
      },
      "writtenOn": "2018-12-05T08:18:10Z",
      "side": 1,
      "message": "I agree. I think for a while we\u0027ve known that we\u0027ll likely require some kind of database to run zuul. We may even choose something that isn\u0027t SQL, but that is a topic for another spec. I think it would be safe to assume for this spec that some sort of database is both required and available. I also think that this change should be part of v4.",
      "parentUuid": "3f79a3b5_4cb91879",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_31de900f",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 219,
      "author": {
        "id": 1
      },
      "writtenOn": "2018-12-03T22:42:14Z",
      "side": 1,
      "message": "It\u0027s possible that everything you wrote here could apply to \"pipelines\" rather than tenants.  I think we should seek to have parallel pipeline processors within a tenant, not just parallel tenant processing.  Fortunately, I think that\u0027s not a big change from this.\n\nWe might accomplish this by having the trigger event processor dispatch to tenant+pipeline rather than just tenant.",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_ac38eccb",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 219,
      "author": {
        "id": 16068
      },
      "writtenOn": "2018-12-04T20:01:36Z",
      "side": 1,
      "message": "Right, I\u0027ll change that. This makes the management events slightly more complex but I think that\u0027s ok. These events like reconfigure or tenant-reconfigure typically operate on tenant level. So we might need an rw lock on the tenant and a normal lock on the pipeline. A pipeline would lock both, a management event would only lock the tenant lock.",
      "parentUuid": "3f79a3b5_31de900f",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_c33ba797",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 219,
      "author": {
        "id": 7069
      },
      "writtenOn": "2018-12-05T08:18:10Z",
      "side": 1,
      "message": "+1 for locking on the pipeline.",
      "parentUuid": "3f79a3b5_ac38eccb",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_76a4e1a4",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 235,
      "author": {
        "id": 6488
      },
      "writtenOn": "2018-12-04T18:26:44Z",
      "side": 1,
      "message": "IMO it\u0027s not enough to have auth and TLS. We will need to keep those secrets encrypted in ZK, since writing anything to ZK means it will be in the ZK transaction log, unlike gearman which keeps the queues in memory. We can have the executors place a public key into ZK, and schedulers then re-encrypt job secrets to that key upon an executor claiming the job.",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_512c4fb0",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 235,
      "author": {
        "id": 16068
      },
      "writtenOn": "2018-12-04T20:01:36Z",
      "side": 1,
      "message": "Interesting point, but this assumes that you can trust your zookeeper less than your scheduler (as it stores the private keys unencrypted)? Is that really a problem (as we do trust the disks of the scheduler)?",
      "parentUuid": "3f79a3b5_76a4e1a4",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f79a3b5_0687780c",
        "filename": "doc/source/developer/specs/scale-out-scheduler.rst",
        "patchSetId": 2
      },
      "lineNbr": 235,
      "author": {
        "id": 6488
      },
      "writtenOn": "2018-12-05T00:13:45Z",
      "side": 1,
      "message": "I\u0027d like for the scheduler to also encrypt the keys on disk so I don\u0027t have to use encrypted volumes. But that\u0027s a story for another day. Suffice to say that you\u0027re right, the trust levels are the same, but I\u0027m holding new development to a higher standard.",
      "revId": "fcd20da6c39729abc70ba2fb1b1b3b386aef76fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    }
  ]
}